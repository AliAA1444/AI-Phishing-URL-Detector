{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6IYjpYlmfeL",
        "outputId": "f1e90274-28f2-48ac-8a77-6a424e8311c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell 1 Fixed: Now scanning subdomains (ww38...)! âœ…\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "import math\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©\n",
        "def calc_entropy(text):\n",
        "    if not text: return 0\n",
        "    entropy = 0\n",
        "    for x in range(256):\n",
        "        p_x = float(text.count(chr(x))) / len(text)\n",
        "        if p_x > 0: entropy += - p_x * math.log(p_x, 2)\n",
        "    return entropy\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡\n",
        "def similar(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„\n",
        "def get_features(url):\n",
        "    my_list = []\n",
        "\n",
        "    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚ ÙƒØ§Ù…Ù„\n",
        "    try:\n",
        "        # ÙŠØ­ÙˆÙ„ http://ww38.gilhub.com/abc Ø§Ù„Ù‰ ww38.gilhub.com\n",
        "        clean_url = url.split('//')[-1].split('/')[0].split('?')[0]\n",
        "        # ÙŠÙ‚Ø³Ù…Ù‡ Ø§Ù„Ù‰ Ø§Ø¬Ø²Ø§Ø¡ ['ww38', 'gilhub', 'com']\n",
        "        domain_parts = clean_url.split('.')\n",
        "    except:\n",
        "        clean_url = url\n",
        "        domain_parts = [url]\n",
        "\n",
        "    # 1. Ø·ÙˆÙ„ Ø§Ù„Ø±Ø§Ø¨Ø·\n",
        "    my_list.append(len(url))\n",
        "\n",
        "    # 2. Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø·\n",
        "    my_list.append(clean_url.count('.'))\n",
        "\n",
        "    # 3. ÙˆØ¬ÙˆØ¯ @\n",
        "    my_list.append(1 if '@' in url else 0)\n",
        "\n",
        "    # 4. Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© (Entropy) Ù„Ø§Ø·ÙˆÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„Ø±Ø§Ø¨Ø·\n",
        "    longest_part = max(domain_parts, key=len) if domain_parts else clean_url\n",
        "    my_list.append(calc_entropy(longest_part))\n",
        "\n",
        "    # 5. IP Check\n",
        "    if re.search(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', url):\n",
        "        my_list.append(1)\n",
        "    else:\n",
        "        my_list.append(0)\n",
        "\n",
        "    # 6. ÙØ­Øµ Ø§Ù„Ø´Ø±Ø·Ø© (Ù†ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ Ø§Ø°Ø§ ÙƒØ§Ù†Øª ÙÙŠ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø§Ø®ÙŠØ± Ù…Ø«Ù„ .com-sa)\n",
        "    if '-' in clean_url:\n",
        "        my_list.append(1)\n",
        "    else:\n",
        "        my_list.append(0)\n",
        "\n",
        "    # 7. ÙƒÙ„Ù…Ø§Øª Ø­Ø³Ø§Ø³Ø©\n",
        "    bad_words = ['login', 'verify', 'update', 'account', 'secure', 'banking', 'confirm']\n",
        "    found_bad = 0\n",
        "    for w in bad_words:\n",
        "        if w in url.lower():\n",
        "            found_bad += 1\n",
        "    my_list.append(found_bad)\n",
        "\n",
        "    # 8. Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© \"ØµÙŠØ§Ø¯ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯\" (Smart Brand Protection)\n",
        "    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©\n",
        "    top_targets = [\n",
        "        'google', 'facebook', 'amazon', 'apple', 'microsoft', 'netflix', 'paypal',\n",
        "        'dropbox', 'instagram', 'twitter', 'linkedin', 'whatsapp',\n",
        "        'absher', 'moi', 'nafath', 'stc', 'jarir', 'github', 'coursera'\n",
        "    ]\n",
        "\n",
        "    is_typosquatting = 0\n",
        "\n",
        "    # Ø§Ù„Ù„ÙˆØ¬ÙŠÙƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯: Ù†ÙØ­Øµ ÙƒÙ„ Ø¬Ø²Ø¡ ÙÙŠ Ø§Ù„Ø±Ø§Ø¨Ø·\n",
        "    for part in domain_parts:\n",
        "        # Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø§Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù‚ØµÙŠØ±Ø©  (ww38, com, sa)\n",
        "        if len(part) < 4:\n",
        "            continue\n",
        "\n",
        "        if part in top_targets: # Ø§Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø§ØµÙ„ÙŠ (github)\n",
        "            continue # Ù‡Ø°Ø§ Ø¬ÙŠØ¯ØŒ Ù„Ø§ ØªØ³ÙˆÙŠ Ø´ÙŠØ¡\n",
        "\n",
        "        # Ø§Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ùˆ Ø§Ù„Ø§ØµÙ„ÙŠØŒ Ù†Ù‚Ø§Ø±Ù†Ù‡ Ø¨Ø§Ù„Ø§Ù‡Ø¯Ø§Ù\n",
        "        for target in top_targets:\n",
        "            ratio = similar(part, target)\n",
        "            # ØªØ´Ø§Ø¨Ù‡ Ø¹Ø§Ù„ÙŠ (ÙÙˆÙ‚ 0.8) Ù„ÙƒÙ† Ù„ÙŠØ³ ØªØ·Ø§Ø¨Ù‚\n",
        "            if ratio > 0.80 and ratio < 1.0:\n",
        "                is_typosquatting = 1\n",
        "                break\n",
        "        if is_typosquatting: break\n",
        "\n",
        "    my_list.append(is_typosquatting)\n",
        "\n",
        "    # 9. Ù†Ø·Ø§Ù‚Ø§Øª Ù…Ø´Ø¨ÙˆÙ‡Ø©\n",
        "    suspicious_tlds = ['.xyz', '.top', '.site', '.vip', '.cc']\n",
        "    is_sus = 0\n",
        "    for tld in suspicious_tlds:\n",
        "        if url.endswith(tld): is_sus = 1\n",
        "    my_list.append(is_sus)\n",
        "\n",
        "    return my_list\n",
        "\n",
        "print(\"Cell 1 Fixed: Now scanning subdomains (ww38...)! âœ…\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6UnPrhs0mAo",
        "outputId": "74ad6a39-7b4a-4d86-9f1d-22f0d4aa9600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Generating Simulation Data...\n",
            "2. Training...\n",
            "âœ… Model Retrained! Ready to detect 'ww38' tricks.\n"
          ]
        }
      ],
      "source": [
        "print(\"1. Generating Simulation Data...\")\n",
        "\n",
        "def get_random_string(length):\n",
        "    return ''.join(random.choice(string.ascii_lowercase) for i in range(length))\n",
        "\n",
        "safe_urls = []\n",
        "phishing_urls = []\n",
        "top_targets = ['google', 'amazon', 'github', 'absher', 'jarir', 'coursera']\n",
        "\n",
        "# 1. Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¢Ù…Ù†Ø©\n",
        "# Ø±ÙˆØ§Ø¨Ø· Ù†Ø¸ÙŠÙØ©\n",
        "for i in range(3000):\n",
        "    dom = random.choice(top_targets)\n",
        "    url = f\"https://www.{dom}.com\"\n",
        "    safe_urls.append(url)\n",
        "\n",
        "# Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù‚Ø¯Ø© (Ù…Ø«Ù„ Ø¬Ø±ÙŠØ±)\n",
        "for i in range(2000):\n",
        "    dom = random.choice(top_targets)\n",
        "    slug = f\"{get_random_string(5)}-{get_random_string(5)}\"\n",
        "    url = f\"https://www.{dom}.com/item/{slug}\"\n",
        "    safe_urls.append(url)\n",
        "\n",
        "# 2. Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø®Ø¨ÙŠØ«Ø©\n",
        "prefixes = ['ww1', 'ww38', 'www-secure', 'web', 'login']\n",
        "for i in range(2000):\n",
        "    target = random.choice(top_targets)\n",
        "    # ØµÙ†Ø§Ø¹Ø© Ø§Ø³Ù… Ù…Ù‚Ù„Ø¯ (github -> gilhub)\n",
        "    fake = list(target)\n",
        "    idx = random.randint(0, len(target)-1)\n",
        "    fake[idx] = random.choice(['l', '1', 'e', 'a'])\n",
        "    fake_target = \"\".join(fake)\n",
        "\n",
        "    if fake_target != target:\n",
        "        prefix = random.choice(prefixes)\n",
        "        # Ø§Ù„Ù†ØªÙŠØ¬Ø©: http://ww38.gilhub.com\n",
        "        url = f\"http://{prefix}.{fake_target}.com\"\n",
        "        phishing_urls.append(url)\n",
        "\n",
        "# Ø¨) ØªÙ„Ø§Ø¹Ø¨ Ø¹Ø§Ø¯ÙŠ\n",
        "for i in range(2000):\n",
        "    target = random.choice(top_targets)\n",
        "    fake = target + \"x\"\n",
        "    url = f\"http://www.{fake}.com\"\n",
        "    phishing_urls.append(url)\n",
        "\n",
        "# Ø¬) IP ÙˆØ¹Ø´ÙˆØ§Ø¦ÙŠØ©\n",
        "for i in range(1000):\n",
        "    url = f\"http://{random.randint(1,255)}.{random.randint(1,255)}/login\"\n",
        "    phishing_urls.append(url)\n",
        "\n",
        "# --- Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ---\n",
        "print(\"2. Training...\")\n",
        "min_len = min(len(safe_urls), len(phishing_urls))\n",
        "safe_urls = safe_urls[:min_len]\n",
        "phishing_urls = phishing_urls[:min_len]\n",
        "\n",
        "all_urls = safe_urls + phishing_urls\n",
        "all_labels = [0]*len(safe_urls) + [1]*len(phishing_urls)\n",
        "combined = list(zip(all_urls, all_labels))\n",
        "random.shuffle(combined)\n",
        "\n",
        "final_features = [get_features(u) for u, l in combined]\n",
        "X = np.array(final_features)\n",
        "y = np.array([l for u, l in combined])\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "print(f\"âœ… Model Retrained! Ready to detect 'ww38' tricks.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PUMpCaPsuCO",
        "outputId": "b7fb7ed2-25cf-43bf-f898-4318cbde9ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ğŸ›¡ï¸ Enterprise AI Phishing Detector ---\n",
            "Type 'exit' to quit.\n",
            "\n",
            "ğŸ‘‰ Enter URL: https://github.com\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://www.jarir.com/asus-vivobook-s-14-oled-laptops-648873.html\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://www.coursera.org/learn/python-basics/ungradedLti/utvs6/values-and-data-types\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: http://gilhub.com\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "ğŸš¨ RESULT: PHISHING / MALICIOUS\n",
            "âš ï¸  Reason: Suspicious pattern detected (Typosquatting or anomaly).\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: http://ww38.gilhub.com/?subid1=20251120-1110-0496-bb4c-4c09e2d69ff1\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "ğŸš¨ RESULT: PHISHING / MALICIOUS\n",
            "âš ï¸  Reason: Suspicious pattern detected (Typosquatting or anomaly).\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://gilhub.com\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "ğŸš¨ RESULT: PHISHING / MALICIOUS\n",
            "âš ï¸  Reason: Suspicious pattern detected (Typosquatting or anomaly).\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://versus.com/en/cpu\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "âœ… RESULT: Safe Website\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://www.offsec.com/kali-training/courses/?utm_source=kali&utm_medium=web&utm_campaign=menu\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://www.kali.org/\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://satr.tuwaiq.edu.sa\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://satr.tuwaiq.edu.sa/educational-content?program_language=Python\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://www.jarir.com\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://sigma2030.com/courses/18\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "âœ… RESULT: Safe Website\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://m.mu.edu.sa/ar/general/171066\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://www.mu.edu.sa/ar\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://sis.mu.edu.sa/login\n",
            "ğŸ” Check: Whitelist Database...\n",
            "âœ… RESULT: Safe (Verified Trusted Domain)\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://edugate.ksu.edu.sa/ksu/init\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "âœ… RESULT: Safe Website\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://imamu.edu.sa/Pages/default.aspx\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "âœ… RESULT: Safe Website\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://istitlaa.ncc.gov.sa/ar/Education/IMSIU/Pages/default.aspx\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "âœ… RESULT: Safe Website\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: https://units.imamu.edu.sa/colleges/Economics/Pages/self_service_system.aspx\n",
            "ğŸ” Check: AI Deep Analysis...\n",
            "âœ… RESULT: Safe Website\n",
            "------------------------------\n",
            "ğŸ‘‰ Enter URL: exit\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "print(\"--- ğŸ›¡ï¸ Enterprise AI Phishing Detector ---\")\n",
        "print(\"âš ï¸  DISCLAIMER: This is an educational project powered by AI.\")\n",
        "print(\"âš ï¸  It provides a prediction based on patterns, NOT a guarantee.\")\n",
        "print(\"âš ï¸  Always verify URLs manually before entering sensitive info.\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Type 'exit' to quit.\\n\")\n",
        "\n",
        "# --- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ Ø§Ù„ÙŠØ¯ÙˆÙŠØ© ---\n",
        "TRUSTED_DOMAINS = {\n",
        "    # 1. Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©\n",
        "    'github.com', 'www.github.com',\n",
        "    'google.com', 'www.google.com',\n",
        "    'youtube.com', 'www.youtube.com',\n",
        "    'facebook.com', 'www.facebook.com',\n",
        "    'amazon.com', 'www.amazon.com',\n",
        "    'twitter.com', 'www.twitter.com', 'x.com', 'www.x.com',\n",
        "    'instagram.com', 'www.instagram.com',\n",
        "    'linkedin.com', 'www.linkedin.com',\n",
        "    'netflix.com', 'www.netflix.com',\n",
        "    'microsoft.com', 'www.microsoft.com',\n",
        "    'apple.com', 'www.apple.com',\n",
        "    'whatsapp.com', 'www.whatsapp.com',\n",
        "\n",
        "    # 2. Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…\n",
        "    'offsec.com', 'www.offsec.com',\n",
        "    'kali.org', 'www.kali.org',\n",
        "    'tuwaiq.edu.sa', 'www.tuwaiq.edu.sa',\n",
        "    'satr.tuwaiq.edu.sa', # Ù…Ù†ØµØ© Ø³Ø·Ø±\n",
        "    'coursera.org', 'www.coursera.org',\n",
        "    'udemy.com', 'www.udemy.com',\n",
        "\n",
        "    # 3. Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ© ÙˆØ§Ù„Ø¬Ø§Ù…Ø¹ÙŠØ©\n",
        "    'absher.sa', 'www.absher.sa',\n",
        "    'moi.gov.sa', 'www.moi.gov.sa',\n",
        "    'jarir.com', 'www.jarir.com',\n",
        "    'stc.com.sa', 'www.stc.com.sa',\n",
        "\n",
        "    # 4. Ù†Ø·Ø§Ù‚Ø§Øª Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©\n",
        "    'majmaah.edu.sa', 'www.majmaah.edu.sa',\n",
        "    'mu.edu.sa', 'www.mu.edu.sa',      # Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø®ØªØµØ±\n",
        "    'm.mu.edu.sa',                     # Ø±Ø§Ø¨Ø· Ø§Ù„Ø¬ÙˆØ§Ù„\n",
        "    'sis.mu.edu.sa',                   # Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ\n",
        "    'edugate.mu.edu.sa'                # Ø§Ù„Ø¨ÙˆØ§Ø¨Ø©\n",
        "}\n",
        "\n",
        "while True:\n",
        "    u = input(\"ğŸ‘‰ Enter URL: \").strip()\n",
        "\n",
        "    if u == 'exit': break\n",
        "    if not u: continue\n",
        "\n",
        "    # 1. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ\n",
        "    try:\n",
        "        # Ù†Ø²ÙŠÙ„ Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„\n",
        "        clean_u = u.replace(\"https://\", \"\").replace(\"http://\", \"\")\n",
        "        # Ù†Ø£Ø®Ø° Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„ Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³Ø§Ø±\n",
        "        domain_check = clean_u.split('/')[0].lower()\n",
        "        # Ù†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙˆØ±Øª\n",
        "        domain_check = domain_check.split(':')[0]\n",
        "    except:\n",
        "        domain_check = u\n",
        "# Ø§Ù„ÙÙ„Ø§ØªØ±\n",
        "    # 2. Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ (Whitelist Check) âœ…\n",
        "    is_whitelisted = False\n",
        "\n",
        "    # Ù‡Ø°Ø§ ÙŠØ³Ù…Ø­ Ø¨Ù…Ø±ÙˆØ± Ø£ÙŠ Ù†Ø·Ø§Ù‚ ÙØ±Ø¹ÙŠ Ù…Ø«Ù„ any.mu.edu.sa\n",
        "    for trusted in TRUSTED_DOMAINS:\n",
        "        if domain_check == trusted or domain_check.endswith(\".\" + trusted):\n",
        "            is_whitelisted = True\n",
        "            break\n",
        "\n",
        "    if is_whitelisted:\n",
        "        print(\"ğŸ” Check: Whitelist Database...\")\n",
        "        print(f\"âœ… RESULT: Safe (Verified Trusted Domain)\")\n",
        "        print(\"-\" * 30)\n",
        "        continue\n",
        "\n",
        "    # 3. Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\n",
        "    feats = get_features(u)\n",
        "    f_array = np.array(feats).reshape(1, -1)\n",
        "    res = rf_model.predict(f_array)[0]\n",
        "\n",
        "    print(\"ğŸ” Check: AI Deep Analysis...\")\n",
        "\n",
        "    if res == 1:\n",
        "        print(\"ğŸš¨ RESULT: PHISHING / MALICIOUS\")\n",
        "        print(\"âš ï¸  Reason: Suspicious pattern detected (Typosquatting or anomaly).\")\n",
        "    else:\n",
        "        print(\"âœ… RESULT: Safe Website\")\n",
        "    print(\"-\" * 30)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}